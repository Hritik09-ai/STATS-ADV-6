{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68356b33-d453-41f0-b850-71a79a99a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUES.1 Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "# the validity of the results.\n",
    "# ANSWER \n",
    "Analysis of Variance (ANOVA) is a statistical method used to test the equality of means among two or more groups. It relies on several assumptions to ensure the validity of its results. Here are the key assumptions for ANOVA and examples of violations that could impact the validity of the results:\n",
    "\n",
    "Assumptions of ANOVA:\n",
    "Independence of observations: The observations within each group are independent of each other.\n",
    "\n",
    "Violation Example: In a study where observations within groups are dependent (e.g., repeated measures on the same subjects over time), this assumption is violated.\n",
    "Normality: The dependent variable follows a normal distribution within each group.\n",
    "\n",
    "Violation Example: If the dependent variable is highly skewed or does not follow a normal distribution within one or more groups, ANOVA results may be biased.\n",
    "Homogeneity of variances (homoscedasticity): The variances of the dependent variable are equal across all groups (homogeneity of variances).\n",
    "\n",
    "Violation Example: If the variances differ significantly between groups (heteroscedasticity), the assumption of homogeneity of variances is violated.\n",
    "Examples of Violations Impacting Validity:\n",
    "Non-independence of observations:\n",
    "\n",
    "Example: In a study measuring the effectiveness of a teaching method where students are nested within classrooms, if the classrooms are the units of randomization but students within the same classroom tend to be more similar to each other, the assumption of independence is violated.\n",
    "Non-normality:\n",
    "\n",
    "Example: In a study comparing reaction times between different age groups, if reaction times are highly skewed within one or more age groups (e.g., due to outliers), the assumption of normality is violated.\n",
    "Heteroscedasticity:\n",
    "\n",
    "Example: Suppose we are comparing the effectiveness of two drugs on blood pressure across different age groups. If the variability in blood pressure measurements differs significantly between age groups (e.g., larger variability in older age groups), the assumption of homogeneity of variances is violated.\n",
    "Impact on Validity:\n",
    "Type I error rate: Violations of assumptions can lead to inflated Type I error rates (false positives), meaning you might conclude there are significant differences between groups when there actually aren't.\n",
    "\n",
    "Type II error rate: Conversely, violations can also increase Type II error rates (false negatives), meaning you might fail to detect significant differences that actually exist.\n",
    "\n",
    "Bias in estimates: Violations can bias the estimates of treatment effects, making them unreliable or invalid.\n",
    "\n",
    "In practice, it's important to assess whether ANOVA assumptions are reasonably met or if alternative methods (such as non-parametric tests or transformations of data) should be considered when assumptions are violated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae9bcd-2db0-43e1-81e4-58ca78365011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f828d-9bc8-4a34-a181-9f0a0342fece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUES.2 What are the three types of ANOVA, and in what situations would each be used?\n",
    "# ANSWER \n",
    "ANOVA (Analysis of Variance) is a statistical technique used to compare means between two or more groups. There are three main types of ANOVA:\n",
    "\n",
    "One-Way ANOVA:\n",
    "\n",
    "Use: One-Way ANOVA is used when you have one independent variable (factor) with two or more levels (groups).\n",
    "Example: You might use One-Way ANOVA to determine whether there are any statistically significant differences in the means of three or more independent (unrelated) groups. For example, comparing the effectiveness of three different teaching methods (A, B, and C) on student performance.\n",
    "Two-Way ANOVA:\n",
    "\n",
    "Use: Two-Way ANOVA is used when you have two independent variables (factors) and you want to know how they jointly affect the dependent variable.\n",
    "Example: Suppose you are studying the effects of both gender (male vs. female) and diet (low-fat vs. high-fat) on cholesterol levels. Two-Way ANOVA could be used to determine whether there are significant main effects of gender, diet, and if there is an interaction effect between gender and diet on cholesterol levels.\n",
    "Repeated Measures ANOVA:\n",
    "\n",
    "Use: Repeated Measures ANOVA is used when measurements are taken on the same subjects at multiple points in time or under different conditions.\n",
    "Example: If you want to study the effect of a drug over time on a group of patients, you might measure their blood pressure before taking the drug, then at 1 month, 3 months, and 6 months after taking the drug. Repeated Measures ANOVA would help determine if there are significant differences in blood pressure across these time points.\n",
    "Summary of Situations:\n",
    "\n",
    "One-Way ANOVA: Used when comparing means across three or more independent groups (one factor).\n",
    "Two-Way ANOVA: Used when examining the influence of two independent variables simultaneously on a dependent variable, including possible interaction effects.\n",
    "Repeated Measures ANOVA: Used when studying changes in a dependent variable across multiple measurements taken on the same subjects over time or under different conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05106ab2-3170-4ddf-a3f9-b4451bccb391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf83ae2-a19e-473f-87c2-561c7552e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUES.3 What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "# ANSWER \n",
    "In Analysis of Variance (ANOVA), the partitioning of variance refers to the division of the total variance observed in a dataset into different components that can be attributed to various sources or factors. This partitioning is crucial because it helps in understanding how much of the total variability in the data can be explained by the factors being studied, and how much is due to random variability or error.\n",
    "\n",
    "Here’s a breakdown of the typical partitioning of variance in a one-way ANOVA, which is one of the simplest forms:\n",
    "\n",
    "Total Variance (Total Sum of Squares, SS_total):\n",
    "\n",
    "This represents the total variability in the dependent variable (response variable) across all observations.\n",
    "Between-Group Variance (Between-Group Sum of Squares, SS_between):\n",
    "\n",
    "This component measures the variability between the group means (if you are comparing means of different groups).\n",
    "Within-Group Variance (Within-Group Sum of Squares, SS_within or SS_error):\n",
    "\n",
    "This represents the variability within each group or condition, after accounting for the differences between group means.\n",
    "Why is understanding partitioning of variance important?\n",
    "\n",
    "Identifying Significant Effects: By partitioning the variance, ANOVA helps determine whether the differences between group means (or effects of factors) are statistically significant. This is done by comparing the variance between groups (SS_between) to the variance within groups (SS_within).\n",
    "\n",
    "Quantifying Effect Size: ANOVA provides measures like the F ratio, which indicates the ratio of variability between groups to the variability within groups. This helps in understanding the magnitude of the effect of the independent variable(s) on the dependent variable.\n",
    "\n",
    "Guiding Further Analysis: Understanding how variance is partitioned can guide further exploration or interpretation of results. For example, if most of the variance is within groups, it suggests that individual differences or random noise might be more influential than the factor(s) being studied.\n",
    "\n",
    "Assumptions and Interpretation: ANOVA assumes certain conditions regarding the distribution of data and variance. Understanding the partitioning of variance helps in interpreting whether these assumptions are reasonably met and guides the choice of appropriate statistical tests.\n",
    "\n",
    "In essence, the partitioning of variance in ANOVA provides a structured way to analyze the contributions of different factors or groups to the overall variability in the data, thereby aiding in rigorous statistical inference and interpretation of experimental results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37fb56d-4e59-4568-929d-e0859d4cab08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19c264b-e16d-4844-b397-48784010d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUES.4 How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "# sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "# ANSWER \n",
    "In a one-way ANOVA, the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) can be calculated using Python. Here’s how you can do it step-by-step:\n",
    "\n",
    "Total Sum of Squares (SST):\n",
    "SST represents the total variance in the dependent variable (response variable).\n",
    "\n",
    "SST = Σ(yi - y_mean)^2\n",
    "\n",
    "where:\n",
    "\n",
    "yi is each individual observation in your dataset,\n",
    "y_mean is the mean of all the observations.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "y = np.array([5, 7, 3, 8, 6, 9, 4])\n",
    "\n",
    "# Calculate SST\n",
    "y_mean = np.mean(y)\n",
    "SST = np.sum((y - y_mean)**2)\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "\n",
    "Explained Sum of Squares (SSE):\n",
    "SSE represents the variability explained by the group means or factors being studied.\n",
    "\n",
    "SSE = Σ(ni * (y_mean_i - y_mean)^2)\n",
    "\n",
    "where:\n",
    "\n",
    "ni is the number of observations in group i,\n",
    "y_mean_i is the mean of group i,\n",
    "y_mean is the overall mean of all observations.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "data = {\n",
    "    'group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "    'value': [5, 7, 3, 8, 6, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate SSE\n",
    "group_means = df.groupby('group')['value'].mean()\n",
    "y_mean = df['value'].mean()\n",
    "SSE = np.sum(df.groupby('group').apply(lambda x: np.sum((x['value'] - group_means[x.name])**2)))\n",
    "\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "\n",
    "Residual Sum of Squares (SSR):\n",
    "SSR represents the unexplained variability or error in the model.\n",
    "\n",
    "SSR = Σ(yi - y_hat)^2\n",
    "\n",
    "where:\n",
    "\n",
    "yi is each individual observation,\n",
    "y_hat is the predicted value (typically the group mean or fitted value).\n",
    "In Python, if you have group-wise data:\n",
    "# Calculate SSR\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n",
    "Here, SST is the Total Sum of Squares calculated earlier, and SSE is the Explained Sum of Squares.\n",
    "\n",
    "These calculations assume you have data structured appropriately for a one-way ANOVA, where you have groups or factors\n",
    "influencing a numeric dependent variable. Adjust the code based on how your data is organized and whether you're using \n",
    "Pandas DataFrames, NumPy arrays, or another data structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d12b6d3-0552-418e-a6c2-d352e1339a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bfb19a6-7f5e-4fb5-b31b-8e31cb3e9fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (0.13.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.23.5)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.9.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Main Effects:\n",
      "C(factor1)               66.125\n",
      "C(factor2)                6.125\n",
      "C(factor1):C(factor2)     0.125\n",
      "Name: sum_sq, dtype: float64\n",
      "\n",
      "Interaction Effect:\n",
      "27.5\n",
      "\n",
      "ANOVA Table:\n",
      "                       sum_sq   df         F    PR(>F)\n",
      "C(factor1)             66.125  1.0  9.618182  0.036175\n",
      "C(factor2)              6.125  1.0  0.890909  0.398676\n",
      "C(factor1):C(factor2)   0.125  1.0  0.018182  0.899251\n",
      "Residual               27.500  4.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# QUES.5 In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "# ANSWER \n",
    "!pip install statsmodels pandas\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "# Example DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'factor1': ['A', 'A', 'B', 'B', 'A', 'A', 'B', 'B'],\n",
    "    'factor2': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "    'response': [10, 12, 8, 9, 15, 17, 6, 8]\n",
    "})\n",
    "formula = 'response ~ C(factor1) + C(factor2) + C(factor1):C(factor2)'\n",
    "model = ols(formula, data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)  # typ=2 for two-way ANOVA\n",
    "\n",
    "# Extract main effects and interaction effect\n",
    "main_effects = anova_table['sum_sq'][:-1]  # Excluding the interaction effect\n",
    "interaction_effect = anova_table['sum_sq'][-1]  # Last row is the interaction effect\n",
    "print(\"Main Effects:\")\n",
    "print(main_effects)\n",
    "print(\"\\nInteraction Effect:\")\n",
    "print(interaction_effect)\n",
    "print(\"\\nANOVA Table:\")\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a0aaeb-94f6-4448-8251-ca86ed1e3d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba295a-8a0a-46df-8eb8-c5ec3f40e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUES.6 Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "# What can you conclude about the differences between the groups, and how would you interpret these\n",
    "# results?\n",
    "# ANSWER \n",
    "Based on the results of the one-way ANOVA you conducted:\n",
    "\n",
    "F-statistic: You obtained an F-statistic of 5.23.\n",
    "\n",
    "P-value: The corresponding p-value is 0.02.\n",
    "\n",
    "Here’s how you can interpret these results:\n",
    "\n",
    "F-statistic (5.23): This statistic indicates the ratio of the variance between groups (treatment effect) to the variance within groups (error variance). A higher F-value suggests that the means of the groups are more different relative to the variability within each group.\n",
    "\n",
    "P-value (0.02): This is the probability of obtaining an F-statistic equal to or more extreme than the one observed, under the assumption that the null hypothesis is true (i.e., there is no difference between group means). A p-value of 0.02 indicates that there is a 2% probability of observing such an F-statistic if the null hypothesis were true.\n",
    "\n",
    "Conclusion:\n",
    "Since the p-value (0.02) is less than the conventional significance level of 0.05 (assuming you are using a significance level of 0.05), you would reject the null hypothesis.\n",
    "\n",
    "Null Hypothesis (H0): There is no significant difference between the means of the groups.\n",
    "Alternative Hypothesis (Ha): At least one group mean is different from the others.\n",
    "Interpretation:\n",
    "Based on the ANOVA results:\n",
    "\n",
    "Differences between groups: There is sufficient evidence to conclude that there are statistically significant differences between the means of the groups you compared.\n",
    "\n",
    "Practical significance: The differences are not only statistically significant (unlikely due to random chance) but also likely to be practically significant (meaningful in the context of your study).\n",
    "\n",
    "Next steps: You may conduct post-hoc tests (e.g., Tukey's HSD, Bonferroni) to determine which specific groups differ from each other. These tests can provide more detailed insights into the nature of the differences.\n",
    "\n",
    "In summary, with an F-statistic of 5.23 and a p-value of 0.02, you have evidence to reject the null hypothesis and conclude that there are significant differences between the groups you studied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc0929-ad95-4755-a71b-72a718dfee18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47dd831-1b75-4727-a66a-f645e6816806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUES.7 In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "# consequences of using different methods to handle missing data?\n",
    "# ANSWER \n",
    "Handling missing data in a repeated measures ANOVA is important to ensure the validity and reliability of your analysis. Here are some common methods to handle missing data and their potential consequences:\n",
    "\n",
    "Listwise deletion (complete case analysis):\n",
    "\n",
    "Method: Exclude any cases with missing data on any variable involved in the analysis.\n",
    "Consequences: Reduces sample size, potentially leading to loss of statistical power and biased results if the missing data are not missing completely at random (MCAR). Also, this method may introduce bias if the missing data are related to the outcome or other variables in the model.\n",
    "Mean/mode substitution:\n",
    "\n",
    "Method: Replace missing values with the mean (for continuous variables) or mode (for categorical variables) of the observed data.\n",
    "Consequences: Alters the distribution of the variables, potentially reducing variability and underestimating standard errors. This method assumes that missing data are missing at random (MAR) and can introduce bias if this assumption is violated.\n",
    "Regression imputation:\n",
    "\n",
    "Method: Predict missing values using regression models based on other variables in the dataset.\n",
    "Consequences: Requires a good model specification and assumes MAR. If the model is misspecified or the assumption is violated, this method can lead to biased estimates and incorrect standard errors.\n",
    "Multiple imputation:\n",
    "\n",
    "Method: Generate multiple plausible values for each missing data point, based on the observed data and assuming an appropriate imputation model.\n",
    "Consequences: Provides more accurate estimates of parameters and standard errors compared to single imputation methods. However, it requires assumptions about the distribution of missing data and can be computationally intensive.\n",
    "Maximum likelihood estimation (MLE):\n",
    "\n",
    "Method: Estimates model parameters directly from the likelihood function, accounting for missing data.\n",
    "Consequences: Provides unbiased estimates if data are MAR. However, it requires complex model specification and computation, and assumptions about the distribution of missing data.\n",
    "Choosing a Method:\n",
    "Nature of Missing Data: Assess whether missing data are MCAR, MAR, or missing not at random (MNAR). MCAR and MAR assumptions are more amenable to imputation methods, while MNAR requires more sophisticated modeling approaches.\n",
    "\n",
    "Sample Size: Consider the impact of each method on sample size and statistical power.\n",
    "\n",
    "Model Assumptions: Ensure that the chosen method aligns with the assumptions of your statistical model.\n",
    "\n",
    "In practice, multiple imputation is often recommended because it provides more robust estimates and standard errors compared to other methods, assuming appropriate model specification. However, the choice of method should be guided by the nature and extent of missing data, as well as the specific requirements of your analysis and the assumptions you can reasonably make about the missing data mechanism.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd989b1c-0f84-4bb4-a398-cc5c26d8725a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cff8a9-74f5-498c-b70c-71b1199810cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUES.8 What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "# an example of a situation where a post-hoc test might be necessary.\n",
    "# ANSWER \n",
    "After conducting an Analysis of Variance (ANOVA) and finding a significant difference among the means of three or more groups, post-hoc tests are used to determine which specific groups differ from each other. Here are some common post-hoc tests and when you would typically use each one:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD) Test:\n",
    "\n",
    "When to use: Use Tukey's HSD when you have equal sample sizes across groups (balanced design) and you want to test all possible pairwise comparisons.\n",
    "Example: In a study comparing the effectiveness of three different teaching methods on exam scores, ANOVA indicates a significant difference among the groups. Tukey's HSD would then be used to identify which pairs of teaching methods differ significantly in their effects on exam scores.\n",
    "Bonferroni Correction:\n",
    "\n",
    "When to use: Bonferroni correction is used when you have unequal sample sizes or variances across groups, and you want to control the family-wise error rate (FWER) for multiple comparisons.\n",
    "Example: Suppose you conduct ANOVA to compare the mean lifespans of four different species of animals. ANOVA shows a significant difference, and you want to use Bonferroni correction to compare the lifespan of each species with every other species while controlling for Type I error.\n",
    "Scheffé's Test:\n",
    "\n",
    "When to use: Scheffé's test is a more conservative test that can be used in situations where you have unequal sample sizes and variances, and you want to test all possible pairwise comparisons.\n",
    "Example: In a clinical trial comparing the effectiveness of four different treatments for a specific disease, ANOVA indicates a significant difference among treatments. Scheffé's test would be used to identify which specific treatments differ significantly in their effectiveness.\n",
    "Duncan's New Multiple Range Test:\n",
    "\n",
    "When to use: Duncan's test is typically used when you have a balanced design (equal sample sizes) and you want to test all possible pairwise comparisons.\n",
    "Example: In an agricultural study comparing the yield of four different fertilizer treatments across multiple fields, ANOVA shows a significant difference. Duncan's test would be used to determine which pairs of fertilizer treatments result in significantly different yields.\n",
    "Example Situation Requiring a Post-Hoc Test:\n",
    "Imagine a study where researchers are investigating the effect of three different diets (low-carb, Mediterranean, and low-fat) on cholesterol levels in patients. They randomly assign participants into these three groups and measure their cholesterol levels after 12 weeks. The ANOVA results indicate a significant difference among the mean cholesterol levels of these three diet groups.\n",
    "\n",
    "To understand which specific diets lead to different cholesterol levels, a post-hoc test like Tukey's HSD or Bonferroni correction would be necessary. This test would help identify if the Mediterranean diet leads to significantly different cholesterol levels compared to the low-carb or low-fat diets, or if there are differences between the low-carb and low-fat diets. Without such a test, the study would only show that there is a difference somewhere among the groups but not which specific comparisons are significant. Thus, a post-hoc test is essential for pinpointing the differences and drawing meaningful conclusions from the study.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61feba2c-2dfe-4d34-9487-8fff2f35fc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1e08dd-bd04-4085-89e2-61acfc426dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 0.1629657873948364\n",
      "P-value: 0.8497745885601445\n",
      "F-statistic: 0.1629657873948364\n",
      "P-value: 0.8497745885601445\n"
     ]
    }
   ],
   "source": [
    "# QUES.9 A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "# 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "# to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "# Report the F-statistic and p-value, and interpret the results.\n",
    "# ANSWER \n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Example weight loss data for each diet (replace with actual data)\n",
    "diet_A = np.array([1.2, 2.4, 0.8, 1.5, 1.0, 2.3, 1.8, 1.2, 1.9, 1.4,\n",
    "                   1.7, 2.2, 1.6, 1.1, 2.0, 1.3, 1.5, 1.8, 1.2, 1.4,\n",
    "                   1.9, 1.3, 1.6, 2.1, 1.5, 1.8, 2.0, 1.2, 1.7, 1.4,\n",
    "                   1.9, 1.1, 1.6, 1.3, 2.2, 1.4, 1.8, 1.5, 1.7, 2.0,\n",
    "                   1.3, 1.6, 1.9, 1.4, 1.8, 2.1, 1.5, 1.7, 1.2, 1.6])\n",
    "\n",
    "diet_B = np.array([1.5, 2.0, 1.8, 1.2, 0.5, 1.9, 1.4, 1.7, 2.2, 1.3,\n",
    "                   1.6, 1.0, 1.8, 1.2, 1.5, 2.1, 1.3, 1.7, 1.4, 1.9,\n",
    "                   1.6, 2.0, 1.4, 1.8, 1.1, 1.7, 1.9, 1.5, 1.2, 1.6,\n",
    "                   1.3, 1.8, 2.2, 1.4, 1.7, 1.5, 1.9, 1.1, 1.6, 2.0,\n",
    "                   1.3, 1.7, 1.4, 1.8, 2.1, 1.5, 1.7, 1.2, 1.6, 1.9])\n",
    "\n",
    "diet_C = np.array([1.0, 1.2, 1.4, 0.9, 1.7, 1.3, 1.6, 1.9, 1.4, 1.8,\n",
    "                   2.1, 1.5, 1.7, 1.2, 1.6, 1.9, 1.3, 1.6, 1.1, 1.8,\n",
    "                   2.0, 1.4, 1.7, 1.5, 1.9, 1.2, 1.6, 1.3, 1.8, 2.2,\n",
    "                   1.4, 1.7, 1.5, 1.9, 1.1, 1.6, 2.0, 1.3, 1.7, 1.4,\n",
    "                   1.8, 2.1, 1.5, 1.7, 1.2, 1.6, 1.9, 1.3, 1.6])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012a56d0-0a78-4a2c-9a6a-cf9b0522f71a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c65dd52c-1f59-4d00-bf47-b5c07e2e9690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (0.13.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.9.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (22.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "                              sum_sq    df         F    PR(>F)\n",
      "C(Software)                11.141545   2.0  2.113814  0.142706\n",
      "C(Experience)               2.102143   1.0  0.797652  0.380665\n",
      "C(Software):C(Experience)   6.013261   2.0  1.140857  0.336272\n",
      "Residual                   63.249921  24.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# QUES.10 A company wants to know if there are any significant differences in the average time it takes to\n",
    "# complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "# randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "# complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "# interaction effects between the software programs and employee experience level (novice vs.\n",
    "# experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "# ANSWER \n",
    "!pip install pandas statsmodels\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create sample data\n",
    "np.random.seed(0)\n",
    "\n",
    "software = np.random.choice(['A', 'B', 'C'], 30)\n",
    "experience = np.random.choice(['novice', 'experienced'], 30)\n",
    "time = np.random.normal(10, 2, 30)\n",
    "\n",
    "df = pd.DataFrame({'Software': software, 'Experience': experience, 'Time': time})\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=df).fit()\n",
    "\n",
    "# Perform ANOVA (type 2)\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5067855-ca33-4c9d-8147-1c5cf939c845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3033ec9e-ec7a-482e-a660-b16c91e87a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "T-statistic: -3.3511267852812807\n",
      "P-value: 0.0009638719426795379\n",
      "ANOVA table:\n",
      "                sum_sq     df          F    PR(>F)\n",
      "Group      1450.490461    1.0  11.230051  0.000964\n",
      "Residual  25573.981649  198.0        NaN       NaN\n",
      "\n",
      "Tukey's HSD results:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1    group2    meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------------\n",
      "Control Experimental   5.3861 0.001 2.2166 8.5556   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# QUES.11 An educational researcher is interested in whether a new teaching method improves student test\n",
    "# scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "# experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "# two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "# between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "# group(s) differ significantly from each other.\n",
    "# ANSWER \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Simulate test scores\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)     # Control group scores\n",
    "experimental_scores = np.random.normal(loc=75, scale=12, size=100)  # Experimental group scores\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Two-sample t-test results:\")\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Combine scores and group labels into a DataFrame\n",
    "scores = np.concatenate([control_scores, experimental_scores])\n",
    "groups = np.array(['Control'] * 100 + ['Experimental'] * 100)\n",
    "df = pd.DataFrame({'Scores': scores, 'Group': groups})\n",
    "\n",
    "# Fit an ANOVA model\n",
    "model = ols('Scores ~ Group', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Perform Tukey's HSD test for post-hoc analysis\n",
    "tukey_results = sm.stats.multicomp.pairwise_tukeyhsd(df['Scores'], df['Group'])\n",
    "\n",
    "# Print the ANOVA table and Tukey's HSD results\n",
    "print(\"ANOVA table:\")\n",
    "print(anova_table)\n",
    "print(\"\\nTukey's HSD results:\")\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09180919-5bc8-41d6-8da4-380a402a2d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf37dec7-91f9-488f-874f-d888cd200f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUES.12 A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "# retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "# on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "# significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "# hoc test to determine which store(s) differ significantly from each other.\n",
    "# ANSWER "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
